{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 5: KB_AVISO_ESM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import scipy.io as sio\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100k segments where when LC-S there is no bloom <br>\n",
    "First application of CMPI6 HR-ESM for solving an environmental problem <br>\n",
    "Redtide/LC is just a case study <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] Extract zos(model) data for AVISO segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCAR: [2] CESM1-CAM5-SE-HR_hist-1950_NR1 (8-9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-23eb37fe55df>:36: UserWarning: WARNING: missing_value not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  vval=var[:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMCC: [3] CMCC-CM2-HR4_hist-1950_NR1 (9-10)\n",
      "CMCC: [4] CMCC-CM2-VHR4_hist-1950_NR1 (10-11)\n",
      "CNRM-CERFACS: [5] CNRM-CM6-1-HR_hist-1950_NR3 (13-16)\n",
      "CNRM-CERFACS: [6] CNRM-CM6-1-HR_historical_NR1 (16-17)\n",
      "E3SM-Project: [7] E3SM-1-0_historical_NR5 (17-22)\n",
      "EC-Earth-Consortium: [8] EC-Earth3P_hist-1950_NR3 (23-26)\n",
      "EC-Earth-Consortium: [9] EC-Earth3P-HR_hist-1950_NR3 (26-29)\n",
      "ECMWF: [10] ECMWF-IFS-HR_hist-1950_NR6 (29-35)\n",
      "ECMWF: [11] ECMWF-IFS-MR_hist-1950_NR3 (35-38)\n",
      "NOAA-GFDL: [12] GFDL-CM4_historical_NR1 (46-47)\n",
      "NOAA-GFDL: [13] GFDL-ESM4_historical_NR2 (47-49)\n",
      "NERC: [14] HadGEM3-GC31-HH_hist-1950_NR1 (49-50)\n",
      "MOHC: [15] HadGEM3-GC31-HM_hist-1950_NR3 (50-53)\n",
      "MOHC: [16] HadGEM3-GC31-MM_hist-1950_NR3 (53-56)\n",
      "MOHC: [17] HadGEM3-GC31-MM_historical_NR4 (56-60)\n"
     ]
    }
   ],
   "source": [
    "#(0) CMIP6.HighResMIP.AWI.AWI-CM-1-1-HR.hist-1950.r1i1p1f2.Omon.zos.gn (1 realizations)       Needs_regridding\n",
    "#(1) CMIP6.CMIP.AWI.AWI-CM-1-1-MR.historical.r1i1p1f1.Omon.zos.gn (5 realizations)            Needs_regridding\n",
    "#(2) CMIP6.HighResMIP.NCAR.CESM1-CAM5-SE-HR.hist-1950.r1i1p1f1.Omon.zos.gn (1 realization)   [Q 3]\n",
    "#(3) CMIP6.HighResMIP.CMCC.CMCC-CM2-HR4.hist-1950.r1i1p1f1.Omon.zos.gn (1 realization) [Q 2]\n",
    "#(4) CMIP6.HighResMIP.CMCC.CMCC-CM2-VHR4.hist-1950.r1i1p1f1.Omon.zos.gn (1 realization) [Q 2]\n",
    "#(5) CMIP6.HighResMIP.CNRM-CERFACS.CNRM-CM6-1-HR.hist-1950.r1i1p1f2.Omon.zos.gn (3 realizations)  [Q 1]\n",
    "#(6) CMIP6.CMIP.CNRM-CERFACS.CNRM-CM6-1-HR.historical.r1i1p1f2.Omon.zos.gn (1 realizations) [Q 1]\n",
    "#(7) CMIP6.CMIP.E3SM-Project.ES3M-1-0.historical.r1i1p1f1.Omon.zos.gr (5 realizations) [Q 0]\n",
    "#(8) CMIP6.HighResMIP.EC-Earth-Consortium.EC-Earth3P-HR.hist-1950.r1i1p2f1.Omon.zos.gn (3 realizations) [Q 0]\n",
    "#(9) CMIP6.HighResMIP.EC-Earth-Consortium.EC-Earth3P.hist-1950.r1i1p2f1.Omon.zos.gn (3 realizations) [Q 4]\n",
    "#(10) CMIP6.HighResMIP.ECMWF.ECMWF-IFS-HR.hist-1950.r1i1p1f1.Omon.zos.gn (6 realizations) [Q 5]\n",
    "#(11) CMIP6.HighResMIP.ECMWF.ECMWF-IFS-MR.hist-1950.r1i1p1f1.Omon.zos.gn (3 realizations)[Q 5]\n",
    "#(12) CMIP6.CMIP.NOAA-GFDL.GFDL-CM4.historical.r1i1p1f1.Omon.zos.gn (1 realizations) [Q 4]\n",
    "#(13) CMIP6.CMIP.NOAA-GFDL.GFDL-ESM4.historical.r2i1p1f1.Omon.zos.gn (2 realizations) [Q 3]\n",
    "#(14) CMIP6.HighResMIP.NERC.HadGEM3-GC31-HH.hist-1950.r1i1p1f1.Omon.zos.gn (1 realization)  [Q 5]\n",
    "#(15) CMIP6.HighResMIP.MOHC.HadGEM3-GC31-HM.hist-1950.r1i1p1f1.Omon.zos.gn (3 realizations) [Q 5]\n",
    "#(16) CMIP6.HighResMIP.MOHC.HadGEM3-GC31-MM.hist-1950.r1i1p1f1.Omon.zos.gn (3 realizations) [Q 5]\n",
    "#(17) CMIP6.CMIP.MOHC.HadGEM3-GC31-MM.historical.r1i1p1f3.Omon.zos.gn (4 realizations) [Q 5]\n",
    "#(18) CMIP6.HighResMIP.MPI-M.MPI-ESM1-2-HR.hist-1950.r1i1p1f1.Omon.zos.gn (1 realization)  Has_error\n",
    "#(19) CMIP6.HighResMIP.MPI-M.MPI-ESM1-2-XR.hist-1950.r1i1p1f1.Omon.zos.gn (1 realization)  Has_error\n",
    "#(20) CMIP6.obs4MIPs.CNES.AVISO-1-0.BE.r0.Omon.zos.gn (1 realization)\n",
    "#(21) CMIP6.obs4MIPs.CMEMS.AVISO-1-0.phy-001-031.r0.Omon.zos.gn (4 realization)\n",
    "#(22) CMIP6.obs4MIPs.CMEMS.AVISO-1-0.phy-001-031.r0.Omon.zos.gn (1 realization)\n",
    "\n",
    "\n",
    "#MI  0  1 #2  3  4   5   6   7   8   9   10  11  12  13  14  15  16  17 #18  19 20  21 22\n",
    "LMN=[0, 2, 8, 9, 10, 13, 16, 17, 23, 26, 29, 35, 46, 47, 49, 50, 53, 56, 69, 70, 81,82,86]\n",
    "\n",
    "# Load table of model processinf info\n",
    "df=pd.read_csv('Input/zos_models.csv')\n",
    "\n",
    "#Loop models and realizations\n",
    "for MI in [*range(2,18)]:\n",
    "    zos_Extract(np,Dataset,df,LMN,MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zos_LoadData(np,Dataset,df,nsim):\n",
    "    \n",
    "    #[1] Information of zos file (e.g., EC-Earth3P_hist-1950_r1i1p2f1.nc)\n",
    "    #Raw CMIP6 with large size is not provided \n",
    "    # butcan be downloaded from following intrustion here https://youtu.be/jf1-AXhFSkU\n",
    "    path=(r'\\\\wsl$/Ubuntu-20.04/home/aelshall/NCO/FLmap/zos/260W285S_17S35N/data/')\n",
    "    file='{}_{}_{}.nc'.format(df.loc[nsim, 'Source_ID'],df.loc[nsim, 'Experiment_ID'],df.loc[nsim, 'Variant_Label'])\n",
    "    realization=df.loc[nsim, 'Variant_Label']\n",
    "        \n",
    "    ### [4] Extract zos(model) data for AVISO segments\n",
    "    #[2] Read netCDF file\n",
    "    #(2.1) Load netCDF file \n",
    "    data= Dataset(path+file,'r')  \n",
    "\n",
    "    #[3] Read lat and lon data\n",
    "    #(3.1) Name of lat and lon dimension variable \n",
    "    if df.loc[nsim,'lat_lon_grid']== 'no':\n",
    "        lat_ID=df.loc[nsim,'lat_1d_ID']\n",
    "        lon_ID=df.loc[nsim,'lon_1d_ID']\n",
    "    else:\n",
    "        lat_ID=df.loc[nsim,'lat_grid_ID']\n",
    "        lon_ID=df.loc[nsim,'lon_grid_ID']\n",
    "    \n",
    "    #(3.2) Read lat and lon data from netCDF variables\n",
    "    lats=data.variables[lat_ID][:]    #-89.5 to  89.5\n",
    "    lons=data.variables[lon_ID][:]    #  0.5 to 359.\n",
    "\n",
    "    #(3.3) lon conversion from 0:360 to 0:180E and 0:-180W with 0 greenwich prime meridian\n",
    "    lons[:][lons[:]>180]-=360\n",
    "\n",
    "    #[4] Read zos data \n",
    "    #(4.1) Check variable information\n",
    "    vnam='zos'\n",
    "    var=data.variables[vnam]\n",
    "\n",
    "\n",
    "    #(4.2) Extract raw zos data\n",
    "    vval=var[:]\n",
    "    \n",
    "    return lats,lons,vval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zos_Extract(np,Dataset,df,LMN,MI):\n",
    "    \n",
    "    #[0]Variables \n",
    "    Start=LMN[MI]\n",
    "    n_realizations=df.loc[Start, 'n_realizations']\n",
    "    End=n_realizations+Start\n",
    "    \n",
    "    Institution_ID=df.loc[Start,'Institution_ID']\n",
    "    Source_ID=df.loc[Start,'Source_ID']\n",
    "    Experiment_ID=df.loc[Start,'Experiment_ID']\n",
    "    print('{}: [{}] {}_{}_NR{} ({}-{})'.\\\n",
    "          format(Institution_ID,MI,Source_ID,Experiment_ID,n_realizations,Start,End))\n",
    "    \n",
    "    for nsim in range(Start,End):          \n",
    "            #[0]Variables \n",
    "            Variant_Label=df.loc[nsim,'Variant_Label']\n",
    "            lat_lon_grid=df.loc[nsim, 'lat_lon_grid']\n",
    "\n",
    "            #[1-4] load data\n",
    "            lats,lons,vval=zos_LoadData(np,Dataset,df,nsim)\n",
    "\n",
    "            Bathymetry=['B300']\n",
    "            for bathymetry in Bathymetry:     \n",
    "                #[5] Read the lat and lon data of two segments from csv files\n",
    "                sNdata=np.loadtxt('Output/DigitizeSegments_Bathymetry_AVISO_{}.csv'.format(bathymetry),delimiter=',')\n",
    "\n",
    "                #[6] Find lat and lon indecies for north and south segments\n",
    "                SP=np.zeros(sNdata.shape).astype(int)  #Need to be type int for indecies\n",
    "                for n in range(sNdata.shape[0]):\n",
    "                    if lat_lon_grid != 'no':\n",
    "                        #index of min squared difference lat and lon\n",
    "                        SP[n,:]=[((lats[:,1]-sNdata[n,0])**2).argmin(), ((lons[1,:]-sNdata[n,1])**2).argmin()] \n",
    "                    elif lat_lon_grid == 'no':\n",
    "                        #index of min squared difference lat and lon\n",
    "                        SP[n,:]=[((lats-sNdata[n,0])**2).argmin(), ((lons-sNdata[n,1])**2).argmin()] \n",
    "\n",
    "                #[7] Extract max SSH data for each segment given indecies\n",
    "                #(7.1) Extract SSH data for all indecies along the norht segment\n",
    "                zos=np.zeros([vval.shape[0],SP.shape[0]])\n",
    "                for n in range(SP.shape[0]):\n",
    "                    zos[:,n]=vval[:,SP[n,0],SP[n,1]]\n",
    "                data=zos[36:,:]\n",
    "                #print(bathymetry,data.shape)\n",
    "                np.savetxt('Output/zos_segments_data_Bathymetry_{}_{}_{}_{}.csv'. \\\n",
    "                           format(bathymetry,Source_ID,Experiment_ID,Variant_Label),data,delimiter=',')           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] Create 3d arrays for different enesembles of models for each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B300 543210 (41, 264, 119) (264, 119)\n",
      "B300 (1, 264, 119)\n"
     ]
    }
   ],
   "source": [
    "#[0] Variables\n",
    "Bathymetry=['B300']\n",
    "NME=['543210']\n",
    "# ME=[[5,-1,-1,-1,-1,-1],[5,4,-1,-1,-1,-1],[5,4,3,-1,-1,-1],[5,4,2,-1,-1,-1],\\\n",
    "#     [5, 4, 1,-1,-1,-1],[5,4, 3, 2,-1,-1],[5,4,3, 2, 1,-1],[5,4,3,2,1,0], [-1, -1, -1,-1,-1,0]]\n",
    "ME=[[5,4,3,2,1,0]]\n",
    "\n",
    "#MI  0  1 #2  3  4   5   6   7   8   9   10  11  12  13  14  15  16  17 #18  19 20  21 22\n",
    "LMN=[0, 2, 8, 9, 10, 13, 16, 17, 23, 26, 29, 35, 46, 47, 49, 50, 53, 56, 69, 70, 81,82,86]\n",
    "df=pd.read_csv('Input/zos_models.csv')\n",
    "\n",
    "#[1] Create 3d array of all models for each segment\n",
    "\n",
    "#(1) Segments\n",
    "for bathymetry in Bathymetry: \n",
    "    bZOS=[]\n",
    "    \n",
    "    #(2) Ensembles\n",
    "    for nme,me in zip(NME,ME):\n",
    "        ZOS=[]\n",
    "\n",
    "        #(3) Models\n",
    "        for MI in [*range(2,18)]:\n",
    "            #[0]Variables \n",
    "            Start=LMN[MI]\n",
    "            n_realizations=df.loc[Start, 'n_realizations']\n",
    "            End=n_realizations+Start\n",
    "            QLTY=df.loc[Start, 'QLTY']\n",
    "\n",
    "            Institution_ID=df.loc[Start,'Institution_ID']\n",
    "            Source_ID=df.loc[Start,'Source_ID']\n",
    "            Experiment_ID=df.loc[Start,'Experiment_ID']\n",
    "\n",
    "            #(4) Realizations \n",
    "            for nsim in range(Start,End): \n",
    "                Variant_Label=df.loc[nsim,'Variant_Label']  \n",
    "                zos=np.loadtxt('Output/zos_segments_data_Bathymetry_{}_{}_{}_{}.csv'. \\\n",
    "                               format(bathymetry,Source_ID,Experiment_ID,Variant_Label),delimiter=',')\n",
    "                zos[zos>1e3]=np.nan\n",
    "                #print('{}: {:.2f}  {:.2f}  {}'.format(bathymetry,np.nanmin(zos),np.nanmax(zos),zos.shape))\n",
    "\n",
    "                if QLTY==me[0] or QLTY==me[1] or QLTY==me[2] or QLTY==me[3] or QLTY==me[4] or QLTY==me[5]:\n",
    "                    ZOS.append(zos) \n",
    "\n",
    "            #Display per model\n",
    "            #c0=count-n_realizations\n",
    "            #print('{}: [{}] {}_{}_NR{} ({}-{}) [QLTY: {}] -> {}:{} '. \\\n",
    "            #      format(Institution_ID,MI,Source_ID,Experiment_ID,n_realizations,Start,End,QLTY,c0,count))\n",
    "        \n",
    "        #zos_EMS(EMS,Time,bathymetry_cell)\n",
    "        ZOS= np.stack(ZOS)\n",
    "        np.save('Output/zos_segments_data_Bathymetry_{}_{}'.format(bathymetry,nme),ZOS) \n",
    "        \n",
    "        #Process an ensemble\n",
    "        zos=np.nanmean(ZOS, axis=0)\n",
    "        np.savetxt('Output/zos_segments_data_Bathymetry_{}_{}.csv'.format(bathymetry,nme),zos,delimiter=',')\n",
    "        print(bathymetry,nme,ZOS.shape,zos.shape)\n",
    "        \n",
    "        #append ensemble to other snsembles for the segment \n",
    "        bZOS.append(zos) \n",
    "    \n",
    "    #Collect all ensembles for each segment \n",
    "    bZOS= np.stack(bZOS)\n",
    "    np.save('Output/zos_segments_data_Bathymetry_{}_Ensembles'.format(bathymetry),bZOS)   \n",
    "    print(bathymetry,bZOS.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
